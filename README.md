# Real-time Convolutional Neural Networks for Emotion and Gender Classification

Repackaged and augmented with data publishing functionality. The source work can be found at https://mas-group.inf.h-brs.de/?page_id=622 and https://github.com/oarriaga/face_classification/blob/master/report.pdf.

## Preconditions

* An Nvidia Jetson TX2
* A connected USB video camera

## Building on a TX2

The following directions assume you've cloned the repository files in `/home/nvidia/face_classification`. To do that, execute:

    git clone https://github.com/michaeldye/face_classification.git /home/nvidia/face_classification

### Local Project Setup

The face classification experiment uses IBM-provided Horizon services to publish data to one or more IBM Cloud data storage and analytics services. The data is generated by a natively-executed Python process. The following steps install the native component of the experiment.

* Install Python virtualenv packages as root:

    sudo su -
    apt update && apt install -y virtualenvwrapper virtualenv
    exit

* End your terminal session (whether remote or local) as user `nvidia`:

    exit

* Create a Python virtual environment:

    mkvirtualenv -p /usr/bin/python3 /home/nvidia/face_classification/venv

* Enter the virtual environment and install dependencies (note that this operation will take about 30mins to complete):

    cd /home/nvidia/face_classification && workon venv
    cd python && pip install -r ./requirements-arm64.txt

### Executing the Experiment

It is assumed that you've already installed the native component of this experiment (see above). The following instructions begin execution of the native component which includes creation of a unix domain socket file handle for communication with the Horizon-managed service containers. You must execute the native component at least once before the Horizon container pattern is executed on the TX2.

* If you haven't aready, enter the virtual environment:

    cd /home/nvidia/face_classification && workon venv

* Start the emotion classification process:

    python ./src/face_emotion.py -c ./src/face_emotion.cfg camera 0

* Setup the TX2 as a Horizon node and configure it to execute a face_classification pattern:

    [TODO]

Once the container pattern is executing on the TX2, serialized data from the emotion classification (native) process is transmitted to your IBM Cloud services for analytics. You can browse to... [TODO]
